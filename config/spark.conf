# ============================================================================
# Spark Configuration for Local Development
# ============================================================================
# This file contains Spark configuration properties for local development.
# These settings optimize Spark for running on a laptop with limited resources.
#
# To use this file, set the following when creating a SparkSession:
#   spark = SparkSession.builder.config(conf=spark_conf).getOrCreate()
#
# Or via spark-submit:
#   spark-submit --properties-file config/spark.conf your_script.py
# ============================================================================

# Application Properties
spark.app.name=HelloWorldSparkApp

# Spark Master
spark.master=local[*]

# Memory Configuration
# Allocate 2GB for the driver (adjust based on your laptop's RAM)
spark.driver.memory=2g
# Allocate 1GB for each executor
spark.executor.memory=1g

# Shuffle Configuration
# Reduce shuffle partitions for local development (default is 200)
spark.sql.shuffle.partitions=4
spark.default.parallelism=4

# Performance Tuning
# Enable adaptive query execution (Spark 3.x)
spark.sql.adaptive.enabled=true

# Broadcast join threshold (data smaller than this will be broadcast)
spark.sql.autoBroadcastJoinThreshold=10485760

# Compression
spark.rdd.compress=true
spark.shuffle.compress=true
spark.shuffle.spill.compress=true

# Logging
# Set log level (ALL, DEBUG, ERROR, FATAL, INFO, OFF, TRACE, WARN)
spark.driver.extraJavaOptions=-Dlog4j.configuration=file:config/log4j.properties

# UI Configuration
spark.ui.enabled=true
spark.ui.port=4040

# Warehouse Directory
spark.sql.warehouse.dir=spark-warehouse

# Dynamic Allocation (disabled for local mode)
spark.dynamicAllocation.enabled=false

# Serialization
spark.serializer=org.apache.spark.serializer.KryoSerializer

# Storage
spark.storage.memoryFraction=0.6
